{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16c15415-1812-4fc4-a830-8a46d961f7a7",
   "metadata": {},
   "source": [
    "What is Feature Engineering?\n",
    "\n",
    "        Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986afec2-bb8e-4604-a84e-ce437221fa0a",
   "metadata": {},
   "source": [
    "**What is Feature Engineering?**\n",
    " \n",
    "            Feature engineering is the process of creating new features or modifying existing ones to improve the performance of machine learning models. It involves techniques like feature extraction, transformation, encoding, and scaling to make data more useful for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce2589d-c6cb-4ae5-8b92-1c575977ff22",
   "metadata": {},
   "source": [
    "**Why Do We Need Feature Engineering?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c033ee7b-3437-4592-ab94-1b0ca5e440ff",
   "metadata": {},
   "source": [
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    "1.**Improves Model Performance** – Good features help models make better predictions.\n",
    " \n",
    "2.**Reduces Overfitting** – Helps eliminate noise and irrelevant data.\n",
    " \n",
    "3.**Handles Missing Data** – Creates meaningful replacements for missing values.\n",
    " \n",
    "4.**Enables Better Interpretability** – Makes features more understandable and useful.\n",
    "\n",
    "5.**Reduces Dimensionality** – Helps remove unnecessary data points, making the model efficient.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33772e17-30b2-4eae-a8ca-7c52fbf951c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TransactionDate  DayOfWeek  Hour  IsWeekend\n",
      "0 2025-02-05 14:30:00          2    14          0\n",
      "1 2025-02-06 18:45:00          3    18          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "#sample dataset\n",
    "df=pd.DataFrame({'TransactionDate':pd.to_datetime(['2025-02-05 14:30:00','2025-02-06 18:45:00'])})\n",
    "# Extract date-relted features\n",
    "df['DayOfWeek']=df['TransactionDate'].dt.dayofweek \n",
    "df['Hour']=df['TransactionDate'].dt.hour\n",
    "df['IsWeekend']=df['DayOfWeek'].apply(lambda x: 1 if x>=5 else 0)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1817cfd-28f9-40a7-a1bb-8887f2e2df4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  AvgTransactionAmount\n",
      "0     101                 600.0\n",
      "1     102                 350.0\n",
      "2     103                1000.0\n"
     ]
    }
   ],
   "source": [
    "#Aggregated features\n",
    "#Find average transaction amount per user:\n",
    "df_transactions=pd.DataFrame({\n",
    "    'UserID':[101,102,101,103,102],\n",
    "    'TransactionAmount':[500,300,700,1000,400]\n",
    "})\n",
    "df_user_avg=df_transactions.groupby('UserID')['TransactionAmount'].mean().reset_index()\n",
    "df_user_avg.rename(columns={'TransactionAmount':'AvgTransactionAmount'},inplace=True)\n",
    "print(df_user_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "787251cb-7c7a-4f72-9b8d-66149a29914b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ProductCategory_Clothing  ProductCategory_Electronics  \\\n",
      "0                       0.0                          1.0   \n",
      "1                       1.0                          0.0   \n",
      "2                       1.0                          0.0   \n",
      "3                       0.0                          0.0   \n",
      "\n",
      "   ProductCategory_Grocery  \n",
      "0                      0.0  \n",
      "1                      0.0  \n",
      "2                      0.0  \n",
      "3                      1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'ProductCategory':['Electronics','Clothing','Clothing','Grocery']})\n",
    "encoder=OneHotEncoder(sparse_output=False)\n",
    "encoded_features=encoder.fit_transform(df[['ProductCategory']])\n",
    "df_encoded=pd.DataFrame(encoded_features,columns=encoder.get_feature_names_out())\n",
    "print(df_encoded)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8699f738-7e32-4a8e-a327-c069ba4cc32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount\n",
      "0                100              4.615121\n",
      "1                200              5.303305\n",
      "2               5000              8.517393\n",
      "3              10000              9.210440\n",
      "4              20000              9.903538\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "df=pd.DataFrame({'TransactionAmount':[100,200,5000,10000,20000]})\n",
    "df['LogTransactionAmount']=np.log1p(df['TransactionAmount'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5078671-6520-4398-a861-3eed18090686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionAmount  LogTransactionAmount  NormalizedTransactionAmount  \\\n",
      "0                100              4.615121                     0.000000   \n",
      "1                200              5.303305                     0.005025   \n",
      "2               5000              8.517393                     0.246231   \n",
      "3              10000              9.210440                     0.497487   \n",
      "4              20000              9.903538                     1.000000   \n",
      "\n",
      "   StandardizedTransactionAmount  \n",
      "0                      -0.937070  \n",
      "1                      -0.923606  \n",
      "2                      -0.277351  \n",
      "3                       0.395831  \n",
      "4                       1.742196  \n"
     ]
    }
   ],
   "source": [
    "#Feature Scaling\n",
    "# Feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    " \n",
    "scaler = MinMaxScaler()\n",
    "df['NormalizedTransactionAmount']=scaler.fit_transform(df[['TransactionAmount']])\n",
    " \n",
    "standard_scaler = StandardScaler()\n",
    "df['StandardizedTransactionAmount']=standard_scaler.fit_transform(df[['TransactionAmount']])\n",
    " \n",
    "print(df)\n",
    " \n",
    "# Ensures all features have the same scale, preventing bias in ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8bda71-39c0-4613-b7a1-b14594bb211e",
   "metadata": {},
   "source": [
    "**Final Summary of Feature Engineering & Imbalanced Data Handling**\n",
    " \n",
    "Feature Extraction : Extract new insights from raw data (e.g., Hour, DayOfWeek)\n",
    " \n",
    "Aggregated Features : Calculate meaningful statistics (e.g., AvgTransactionAmountPerUser)\n",
    " \n",
    "Encoding : Convert categorical variables into numerical (One-Hot Encoding)\n",
    " \n",
    "Log Transformation : Reduce skewness in data distribution\n",
    " \n",
    "Feature Scaling : Normalize numerical features for better model performance\n",
    " \n",
    "Downsampling: Reduce the size of the majority class\n",
    " \n",
    "Upsampling : Increase the size of the minority class\n",
    " \n",
    "SMOTE(Synthetic Minority Over-sampling Technique) : Generate synthetic samples for the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caa3996-8bdf-4439-aedc-8a29ad6d6938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
